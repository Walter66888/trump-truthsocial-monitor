import os
import requests
import json
import time
import random
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import hashlib
import sqlite3
from datetime import datetime
import logging
import traceback

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# ç¯å¢ƒå˜é‡é…ç½®
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_GROUP_ID = os.environ.get("LINE_GROUP_ID")

# éªŒè¯ç¯å¢ƒå˜é‡
if not DEEPSEEK_API_KEY:
    logger.error("æœªè®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
    raise ValueError("å¿…é¡»è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
    
if not LINE_CHANNEL_ACCESS_TOKEN:
    logger.error("æœªè®¾ç½® LINE_CHANNEL_ACCESS_TOKEN ç¯å¢ƒå˜é‡")
    raise ValueError("å¿…é¡»è®¾ç½® LINE_CHANNEL_ACCESS_TOKEN ç¯å¢ƒå˜é‡")
    
if not LINE_GROUP_ID:
    logger.error("æœªè®¾ç½® LINE_GROUP_ID ç¯å¢ƒå˜é‡")
    raise ValueError("å¿…é¡»è®¾ç½® LINE_GROUP_ID ç¯å¢ƒå˜é‡")

# Truth Social URL
TRUTH_URL = "https://truthsocial.com/@realDonaldTrump"

# è®¾ç½®æ—¥å¿—é¡¶éƒ¨
def log_startup():
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info("=" * 50)
    logger.info(f"è„šæœ¬å¯åŠ¨æ—¶é—´: {current_time}")
    logger.info("=" * 50)

# è„šæœ¬ç»“æŸæ—¶çš„æ—¥å¿—
def log_shutdown():
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info("=" * 50)
    logger.info(f"è„šæœ¬ç»“æŸæ—¶é—´: {current_time}")
    logger.info("=" * 50)

# åˆå§‹åŒ–æ•°æ®åº“
def init_db():
    conn = sqlite3.connect('posts.db')
    cursor = conn.cursor()
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS posts (
        post_id TEXT PRIMARY KEY,
        content TEXT,
        created_at TIMESTAMP
    )
    ''')
    conn.commit()
    conn.close()
    logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

# æ£€æŸ¥è´´æ–‡æ˜¯å¦å·²å­˜åœ¨
def is_post_exists(post_id):
    conn = sqlite3.connect('posts.db')
    cursor = conn.cursor()
    cursor.execute("SELECT 1 FROM posts WHERE post_id = ?", (post_id,))
    exists = cursor.fetchone() is not None
    conn.close()
    return exists

# ä¿å­˜æ–°è´´æ–‡
def save_post(post_id, content):
    conn = sqlite3.connect('posts.db')
    cursor = conn.cursor()
    cursor.execute(
        "INSERT INTO posts (post_id, content, created_at) VALUES (?, ?, ?)",
        (post_id, content, datetime.now())
    )
    conn.commit()
    conn.close()
    logger.info(f"ä¿å­˜è´´æ–‡ ID: {post_id}")

# é…ç½® Selenium
def setup_selenium():
    logger.info("è®¾ç½® Selenium")
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-extensions")
    
    # ä½¿ç”¨ç³»ç»Ÿå®‰è£…çš„ Chromium
    chrome_bin = os.environ.get("CHROME_BIN", "/usr/bin/chromium")
    chrome_options.binary_location = chrome_bin
    
    # ä½¿ç”¨ç³»ç»Ÿå®‰è£…çš„ chromedriver
    try:
        driver = webdriver.Chrome(options=chrome_options)
        logger.info("æˆåŠŸä½¿ç”¨ç³»ç»Ÿ chromedriver å»ºç«‹ driver")
        return driver
    except Exception as e:
        logger.error(f"å»ºç«‹ driver å¤±è´¥: {e}")
        raise

# å°è¯•ä½¿ç”¨è™šæ‹Ÿæµè§ˆå™¨æŠ€æœ¯çˆ¬å–
def scrape_truth_social():
    logger.info("å¼€å§‹çˆ¬å– Truth Social")
    
    driver = None
    
    try:
        driver = setup_selenium()
        
        # æ·»åŠ éšæœºç”¨æˆ·ä»£ç†
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36'
        ]
        driver.execute_cdp_cmd('Network.setUserAgentOverride', {"userAgent": random.choice(user_agents)})
        
        # è®¿é—®é¡µé¢
        driver.get(TRUTH_URL)
        logger.info("å·²è®¿é—® Truth Social é¡µé¢")
        
        # ç­‰å¾…è¾ƒé•¿æ—¶é—´ç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
        logger.info("ç­‰å¾…é¡µé¢åŠ è½½...")
        time.sleep(10)
        
        try:
            # å°è¯•è·å–é¡µé¢æºä»£ç 
            page_source = driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # å°è¯•å„ç§é€‰æ‹©å™¨
            post_elements = []
            selectors = [
                'article', 
                'div.status-card', 
                'div.status-wrapper', 
                'div.post', 
                'div.truth'
            ]
            
            for selector in selectors:
                elements = soup.select(selector)
                if elements:
                    logger.info(f"æ‰¾åˆ° {len(elements)} ä¸ªåŒ¹é… '{selector}' çš„å…ƒç´ ")
                    post_elements = elements
                    break
            
            if not post_elements:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•æ‰¾ä»»ä½•å¯èƒ½çš„è´´æ–‡
                post_candidates = soup.find_all('div', class_=lambda c: c and ('post' in c.lower() or 'status' in c.lower() or 'truth' in c.lower()))
                if post_candidates:
                    logger.info(f"æ‰¾åˆ° {len(post_candidates)} ä¸ªå¯èƒ½çš„è´´æ–‡å…ƒç´ ")
                    post_elements = post_candidates
            
            if not post_elements:
                logger.warning("æ— æ³•æ‰¾åˆ°ä»»ä½•è´´æ–‡å…ƒç´ ")
                
                # æœ€åå°è¯•ï¼šè·å–ä½¿ç”¨ AJAX åŠ è½½çš„å†…å®¹
                try:
                    logger.info("å°è¯•é€šè¿‡ç›´æ¥ API è¯·æ±‚è·å–è´´æ–‡...")
                    
                    # å°è¯•ä½¿ç”¨ requests ç›´æ¥è·å– API æ•°æ®
                    api_url = f"https://truthsocial.com/api/v1/accounts/realDonaldTrump/statuses"
                    headers = {
                        'User-Agent': random.choice(user_agents),
                        'Accept': 'application/json'
                    }
                    
                    response = requests.get(api_url, headers=headers)
                    if response.status_code == 200:
                        data = response.json()
                        if data and len(data) > 0:
                            latest_truth = data[0]
                            content = latest_truth.get('content', '')
                            
                            # æ¸…ç† HTML æ ‡ç­¾
                            content_soup = BeautifulSoup(content, 'html.parser')
                            clean_content = content_soup.get_text()
                            
                            post_id = str(latest_truth.get('id'))
                            
                            # è·å–åª’ä½“ URL
                            media_urls = []
                            media_attachments = latest_truth.get('media_attachments', [])
                            for media in media_attachments:
                                url = media.get('url')
                                if url:
                                    media_urls.append(url)
                            
                            logger.info(f"é€šè¿‡ API è·å–åˆ°è´´æ–‡ï¼ŒID: {post_id}")
                            return {
                                'id': post_id,
                                'content': clean_content,
                                'media_urls': media_urls
                            }
                    
                    logger.warning(f"API è¯·æ±‚å¤±è´¥æˆ–æ²¡æœ‰æ•°æ®: {response.status_code}")
                except Exception as e:
                    logger.error(f"API è¯·æ±‚å¤±è´¥: {e}")
                
                return None
            
            # è·å–æœ€æ–°çš„è´´æ–‡
            latest_post = post_elements[0]
            
            # å°è¯•æå–æ–‡æœ¬å†…å®¹
            content = None
            content_selectors = [
                'div.status-content', 
                'div.status-body', 
                'div.post-content', 
                'p', 
                'div.text'
            ]
            
            for selector in content_selectors:
                element = latest_post.select_one(selector)
                if element:
                    content = element.get_text(strip=True)
                    logger.info(f"ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ°å†…å®¹")
                    break
            
            if not content:
                # å¦‚æœæ‰¾ä¸åˆ°ç‰¹å®šå…ƒç´ ï¼Œå°è¯•æå–æ‰€æœ‰æ–‡æœ¬
                content = latest_post.get_text(separator=' ', strip=True)
                logger.info("ä½¿ç”¨æ•´ä¸ªå…ƒç´ çš„æ–‡æœ¬ä½œä¸ºå†…å®¹")
            
            if not content:
                logger.warning("æ— æ³•æå–è´´æ–‡å†…å®¹")
                return None
            
            # ç”Ÿæˆå”¯ä¸€ID
            post_id = hashlib.md5(content.encode()).hexdigest()
            
            # æŸ¥æ‰¾åª’ä½“
            media_urls = []
            for img in latest_post.find_all('img'):
                src = img.get('src')
                if src and not src.endswith(('.svg', '.ico')):
                    if not src.startswith(('http://', 'https://')):
                        src = f"https://truthsocial.com{src}" if src.startswith('/') else f"https://truthsocial.com/{src}"
                    media_urls.append(src)
            
            for video in latest_post.find_all('video'):
                src = video.get('src')
                if src:
                    if not src.startswith(('http://', 'https://')):
                        src = f"https://truthsocial.com{src}" if src.startswith('/') else f"https://truthsocial.com/{src}"
                    media_urls.append(src)
            
            logger.info(f"æ‰¾åˆ°è´´æ–‡ï¼ŒID: {post_id}, åª’ä½“æ•°é‡: {len(media_urls)}")
            return {
                'id': post_id,
                'content': content,
                'media_urls': media_urls
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†é¡µé¢æ—¶å‡ºé”™: {e}")
            logger.error(traceback.format_exc())
            return None
            
    except Exception as e:
        logger.error(f"çˆ¬å–å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return None
        
    finally:
        if driver:
            driver.quit()
            logger.info("Selenium driver å·²å…³é—­")

# ä½¿ç”¨ DeepSeek API ç¿»è¯‘å†…å®¹
def translate_with_deepseek(text):
    logger.info("ä½¿ç”¨ DeepSeek API ç¿»è¯‘")
    
    try:
        # ä½¿ç”¨ OpenAI SDK çš„æ–¹å¼æ¥è°ƒç”¨ DeepSeek API
        from openai import OpenAI
        
        client = OpenAI(
            api_key=DEEPSEEK_API_KEY,
            base_url="https://api.deepseek.com"
        )
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šç¿»è¯‘ï¼Œè¯·å°†ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ã€‚ä¿æŒåŸæ„ï¼Œä½¿è¯­è¨€æµç•…è‡ªç„¶ã€‚"},
                {"role": "user", "content": text}
            ],
            temperature=0.3,
            stream=False
        )
        
        translated_text = response.choices[0].message.content
        logger.info("ç¿»è¯‘å®Œæˆ")
        return translated_text
        
    except Exception as e:
        logger.error(f"ç¿»è¯‘å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return f"[ç¿»è¯‘é”™è¯¯] åŸæ–‡: {text}"

# å†…å®¹åˆ†æï¼ˆåˆ¤æ–­æ˜¯æ–‡å­—è¿˜æ˜¯è§†é¢‘ï¼‰
def analyze_content(post):
    if not post:
        return None
        
    # æ£€æŸ¥æ˜¯å¦åŒ…å«è§†é¢‘
    is_video = any(url.endswith(('.mp4', '.avi', '.mov', '.webm')) for url in post.get('media_urls', []))
    
    # ç¿»è¯‘æ–‡æœ¬å†…å®¹
    translated_content = translate_with_deepseek(post['content'])
    
    result = {
        'id': post['id'],
        'original_content': post['content'],
        'translated_content': translated_content,
        'media_urls': post['media_urls'],
        'is_video': is_video
    }
    
    content_type = "å½±ç‰‡" if is_video else "æ–‡å­—"
    logger.info(f"å†…å®¹ç±»å‹: {content_type}")
    
    return result

# å‘é€æ¶ˆæ¯åˆ° LINE ç¾¤ç»„
def send_to_line_group(message):
    logger.info(f"å‘é€æ¶ˆæ¯åˆ° LINE ç¾¤ç»„: {message[:50]}...")
    
    if not LINE_CHANNEL_ACCESS_TOKEN:
        error = "ERROR: LINE_CHANNEL_ACCESS_TOKEN æœªè®¾ç½®"
        logger.error(error)
        return False
        
    if not LINE_GROUP_ID:
        error = "ERROR: LINE_GROUP_ID æœªè®¾ç½®"
        logger.error(error)
        return False
    
    url = 'https://api.line.me/v2/bot/message/push'
    
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {LINE_CHANNEL_ACCESS_TOKEN}'
    }
    
    data = {
        'to': LINE_GROUP_ID,
        'messages': [
            {
                'type': 'text',
                'text': message
            }
        ]
    }
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        
        # è¾“å‡ºè¯¦ç»†å“åº”
        logger.info(f"LINE API å“åº”çŠ¶æ€ç : {response.status_code}")
        logger.info(f"LINE API å“åº”å†…å®¹: {response.text}")
        
        response.raise_for_status()
        logger.info("LINE æ¶ˆæ¯å‘é€æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"LINE æ¶ˆæ¯å‘é€å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return False

# ä¸»æµç¨‹
def main():
    try:
        log_startup()
        
        # ç¬¬ä¸€æ¬¡å¯åŠ¨æ—¶å‘é€é€šçŸ¥ï¼Œç”¨äºç¡®è®¤æœºå™¨äººæ­£å¸¸å·¥ä½œ
        first_run_file = "first_run_completed.txt"
        first_run = not os.path.exists(first_run_file)
        
        if first_run:
            send_to_line_group("ğŸ¤– Trump ç›‘æ§æœºå™¨äººé¦–æ¬¡å¯åŠ¨ï¼Œæ­£åœ¨æ£€æŸ¥ Truth Social...")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        init_db()
        
        # çˆ¬å–æœ€æ–°è´´æ–‡
        latest_post = scrape_truth_social()
        
        if not latest_post:
            if first_run:
                send_to_line_group("ğŸ” é¦–æ¬¡çˆ¬å–æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è´´æ–‡ï¼Œå¯èƒ½æ˜¯ç½‘é¡µç»“æ„å˜åŒ–æˆ–è€…çˆ¬è™«é—®é¢˜ã€‚")
            return
            
        # åªåœ¨é¦–æ¬¡è¿è¡Œæ—¶å‘é€çˆ¬å–ç»“æœé€šçŸ¥
        if first_run:
            post_info = f"âœ… é¦–æ¬¡çˆ¬å–æˆåŠŸï¼æ‰¾åˆ°è´´æ–‡ï¼\n\nID: {latest_post['id']}\n\nå†…å®¹: {latest_post['content'][:100]}...\n\nåª’ä½“æ•°é‡: {len(latest_post['media_urls'])}"
            send_to_line_group(post_info)
            # æ ‡è®°é¦–æ¬¡è¿è¡Œå·²å®Œæˆ
            with open(first_run_file, "w") as f:
                f.write("completed")
        
        # æ£€æŸ¥è´´æ–‡æ˜¯å¦å·²å­˜åœ¨
        if is_post_exists(latest_post['id']):
            logger.info(f"è´´æ–‡ {latest_post['id']} å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†")
            return  # é™é»˜è·³è¿‡ï¼Œä¸å‘é€é€šçŸ¥
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå½±ç‰‡è´´æ–‡
        is_video = any(url.endswith(('.mp4', '.avi', '.mov', '.webm')) for url in latest_post.get('media_urls', []))
        
        if is_video:
            # é™é»˜ç•¥è¿‡å½±ç‰‡è´´æ–‡ï¼Œä½†ä»ç„¶ä¿å­˜åˆ°æ•°æ®åº“
            logger.info("æ£€æµ‹åˆ°å½±ç‰‡è´´æ–‡ï¼Œç•¥è¿‡å¤„ç†")
            save_post(latest_post['id'], latest_post['content'])
            return
            
        # åˆ†æå¹¶ç¿»è¯‘å†…å®¹ï¼ˆä¸å‘é€è¿›åº¦é€šçŸ¥ï¼‰
        logger.info("å¼€å§‹åˆ†æå¹¶ç¿»è¯‘å†…å®¹")
        processed_content = analyze_content(latest_post)
        
        if not processed_content:
            logger.error("å†…å®¹å¤„ç†å¤±è´¥")
            return  # å¤„ç†å¤±è´¥ï¼Œé™é»˜è·³è¿‡
            
        # æ„å»º LINE æ¶ˆæ¯
        message = f"ğŸ”” Trump åœ¨ Truth Social æœ‰æ–°åŠ¨æ€ï¼\n\nğŸ“ ç±»å‹: æ–‡å­—\n\nğŸ‡ºğŸ‡¸ åŸæ–‡:\n{processed_content['original_content']}\n\nğŸ‡¹ğŸ‡¼ ä¸­æ–‡ç¿»è¯‘:\n{processed_content['translated_content']}"
        
        # å¦‚æœæœ‰åª’ä½“ä½†ä¸æ˜¯è§†é¢‘ï¼Œé™„åŠ åª’ä½“ URL
        if processed_content['media_urls']:
            message += "\n\nğŸ–¼ï¸ åª’ä½“é“¾æ¥:\n" + "\n".join(processed_content['media_urls'])
        
        # å‘é€åˆ° LINE ç¾¤ç»„
        logger.info("å‡†å¤‡å‘é€æ¶ˆæ¯åˆ° LINE ç¾¤ç»„")
        if send_to_line_group(message):
            # ä¿å­˜å·²å¤„ç†çš„è´´æ–‡
            save_post(processed_content['id'], processed_content['original_content'])
            logger.info("å¤„ç†å®Œæˆï¼Œè´´æ–‡å·²ä¿å­˜")
        
    except Exception as e:
        logger.error(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        # åªåœ¨é¦–æ¬¡è¿è¡Œæ—¶å‘é€é”™è¯¯é€šçŸ¥
        if first_run:
            error_message = f"âŒ é¦–æ¬¡æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            send_to_line_group(error_message)
    finally:
        log_shutdown()

if __name__ == "__main__":
    main()
