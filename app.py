import os
import requests
import json
import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import hashlib
import sqlite3
from datetime import datetime
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# ç’°å¢ƒè®Šæ•¸é…ç½®
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_GROUP_ID = os.environ.get("LINE_GROUP_ID")

# é©—è­‰ç’°å¢ƒè®Šæ•¸
if not DEEPSEEK_API_KEY:
    logger.error("æœªè¨­ç½® DEEPSEEK_API_KEY ç’°å¢ƒè®Šæ•¸")
    raise ValueError("å¿…é ˆè¨­ç½® DEEPSEEK_API_KEY ç’°å¢ƒè®Šæ•¸")
    
if not LINE_CHANNEL_ACCESS_TOKEN:
    logger.error("æœªè¨­ç½® LINE_CHANNEL_ACCESS_TOKEN ç’°å¢ƒè®Šæ•¸")
    raise ValueError("å¿…é ˆè¨­ç½® LINE_CHANNEL_ACCESS_TOKEN ç’°å¢ƒè®Šæ•¸")
    
if not LINE_GROUP_ID:
    logger.error("æœªè¨­ç½® LINE_GROUP_ID ç’°å¢ƒè®Šæ•¸")
    raise ValueError("å¿…é ˆè¨­ç½® LINE_GROUP_ID ç’°å¢ƒè®Šæ•¸")

# Truth Social URL
TRUTH_URL = "https://truthsocial.com/@realDonaldTrump"

# åˆå§‹åŒ–æ•¸æ“šåº«
def init_db():
    conn = sqlite3.connect('posts.db')
    cursor = conn.cursor()
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS posts (
        post_id TEXT PRIMARY KEY,
        content TEXT,
        created_at TIMESTAMP
    )
    ''')
    conn.commit()
    conn.close()

# æª¢æŸ¥è²¼æ–‡æ˜¯å¦å·²å­˜åœ¨
def is_post_exists(post_id):
    conn = sqlite3.connect('posts.db')
    cursor = conn.cursor()
    cursor.execute("SELECT 1 FROM posts WHERE post_id = ?", (post_id,))
    exists = cursor.fetchone() is not None
    conn.close()
    return exists

# ä¿å­˜æ–°è²¼æ–‡
def save_post(post_id, content):
    conn = sqlite3.connect('posts.db')
    cursor = conn.cursor()
    cursor.execute(
        "INSERT INTO posts (post_id, content, created_at) VALUES (?, ?, ?)",
        (post_id, content, datetime.now())
    )
    conn.commit()
    conn.close()

# é…ç½® Selenium
def setup_selenium():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    
    if os.environ.get('RENDER'):
        chrome_bin = os.environ.get("CHROME_BIN", "/usr/bin/google-chrome-stable")
        chrome_options.binary_location = chrome_bin
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver

# çˆ¬å– Truth Social è²¼æ–‡
def scrape_truth_social():
    logger.info("é–‹å§‹çˆ¬å– Truth Social")
    
    driver = None
    
    try:
        driver = setup_selenium()
        driver.get(TRUTH_URL)
        
        # ç­‰å¾…é é¢åŠ è¼‰
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "article.status-card, div.status-wrapper"))
        )
        
        # ç¢ºä¿é é¢å®Œå…¨åŠ è¼‰
        time.sleep(5)
        
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # å°‹æ‰¾æœ€æ–°çš„è²¼æ–‡
        posts = soup.select('article.status-card, div.status-wrapper')
        
        if not posts:
            logger.warning("æ²’æœ‰æ‰¾åˆ°è²¼æ–‡")
            return None
        
        latest_post = posts[0]
        
        # æå–è²¼æ–‡å…§å®¹
        content_element = latest_post.select_one('div.status-content, div.status-body')
        if not content_element:
            logger.warning("æ‰¾ä¸åˆ°è²¼æ–‡å…§å®¹å…ƒç´ ")
            return None
            
        content = content_element.text.strip()
        
        # ç”Ÿæˆè²¼æ–‡ ID
        post_id = hashlib.md5(content.encode()).hexdigest()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åª’é«”
        media = latest_post.select('div.media-gallery img, div.media-gallery video, div.media-attachment img, div.media-attachment video')
        media_urls = []
        
        for item in media:
            src = item.get('src') or item.get('data-src')
            if src:
                if not src.startswith(('http://', 'https://')):
                    src = f"https://truthsocial.com{src}" if src.startswith('/') else f"https://truthsocial.com/{src}"
                media_urls.append(src)
        
        return {
            'id': post_id,
            'content': content,
            'media_urls': media_urls
        }
        
    except Exception as e:
        logger.error(f"çˆ¬å–å¤±æ•—: {e}")
        return None
    
    finally:
        if driver:
            driver.quit()

# ä½¿ç”¨ DeepSeek API ç¿»è­¯å…§å®¹
def translate_with_deepseek(text):
    logger.info("ä½¿ç”¨ DeepSeek API ç¿»è­¯")
    
    api_url = "https://api.deepseek.com/v1/chat/completions"
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    }
    
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­ç¿»è­¯ï¼Œè«‹å°‡ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è­¯æˆä¸­æ–‡ã€‚ä¿æŒåŸæ„ï¼Œä½¿èªè¨€æµæš¢è‡ªç„¶ã€‚"},
            {"role": "user", "content": text}
        ],
        "temperature": 0.3
    }
    
    try:
        response = requests.post(api_url, headers=headers, json=payload)
        response.raise_for_status()
        
        result = response.json()
        translated_text = result.get('choices', [{}])[0].get('message', {}).get('content', '')
        
        return translated_text
    
    except Exception as e:
        logger.error(f"ç¿»è­¯å¤±æ•—: {e}")
        return f"[ç¿»è­¯éŒ¯èª¤] åŸæ–‡: {text}"

# å…§å®¹åˆ†æï¼ˆåˆ¤æ–·æ˜¯æ–‡å­—é‚„æ˜¯è¦–é »ï¼‰
def analyze_content(post):
    if not post:
        return None
        
    # æª¢æŸ¥æ˜¯å¦åŒ…å«è¦–é »
    is_video = any(url.endswith(('.mp4', '.avi', '.mov', '.webm')) for url in post.get('media_urls', []))
    
    # ç¿»è­¯æ–‡æœ¬å…§å®¹
    translated_content = translate_with_deepseek(post['content'])
    
    result = {
        'id': post['id'],
        'original_content': post['content'],
        'translated_content': translated_content,
        'media_urls': post['media_urls'],
        'is_video': is_video
    }
    
    content_type = "å½±ç‰‡" if is_video else "æ–‡å­—"
    logger.info(f"å…§å®¹é¡å‹: {content_type}")
    
    return result

# ç™¼é€æ¶ˆæ¯åˆ° LINE ç¾¤çµ„
def send_to_line_group(message):
    logger.info(f"ç™¼é€æ¶ˆæ¯åˆ° LINE ç¾¤çµ„: {message[:50]}...")
    
    if not LINE_CHANNEL_ACCESS_TOKEN:
        error = "ERROR: LINE_CHANNEL_ACCESS_TOKEN æœªè¨­ç½®"
        logger.error(error)
        return False
        
    if not LINE_GROUP_ID:
        error = "ERROR: LINE_GROUP_ID æœªè¨­ç½®"
        logger.error(error)
        return False
    
    url = 'https://api.line.me/v2/bot/message/push'
    
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {LINE_CHANNEL_ACCESS_TOKEN}'
    }
    
    data = {
        'to': LINE_GROUP_ID,
        'messages': [
            {
                'type': 'text',
                'text': message
            }
        ]
    }
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        
        # è¼¸å‡ºè©³ç´°å›æ‡‰
        logger.info(f"LINE API éŸ¿æ‡‰ç‹€æ…‹ç¢¼: {response.status_code}")
        logger.info(f"LINE API éŸ¿æ‡‰å…§å®¹: {response.text}")
        
        response.raise_for_status()
        logger.info("LINE æ¶ˆæ¯ç™¼é€æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"LINE æ¶ˆæ¯ç™¼é€å¤±æ•—: {e}")
        return False

# ä¸»æµç¨‹
# ä¸»æµç¨‹
def main():
    try:
        # ç™¼é€å•Ÿå‹•é€šçŸ¥
        send_to_line_group("ğŸ¤– Trump ç›£æ§æ©Ÿå™¨äººå·²å•Ÿå‹•ï¼Œæ­£åœ¨æª¢æŸ¥ Truth Social...")
        
        # åˆå§‹åŒ–æ•¸æ“šåº«
        init_db()
        
        # çˆ¬å–æœ€æ–°è²¼æ–‡
        latest_post = scrape_truth_social()
        
        if not latest_post:
            message = "ğŸ” æ²’æœ‰æ‰¾åˆ°ä»»ä½•è²¼æ–‡ï¼Œå¯èƒ½æ˜¯ç¶²é çµæ§‹è®ŠåŒ–æˆ–è€…çˆ¬èŸ²å•é¡Œã€‚"
            send_to_line_group(message)
            return
            
        # ç™¼é€çˆ¬å–çµæœé€šçŸ¥
        post_info = f"âœ… æ‰¾åˆ°è²¼æ–‡ï¼\n\nID: {latest_post['id']}\n\nå…§å®¹: {latest_post['content'][:100]}...\n\nåª’é«”æ•¸é‡: {len(latest_post['media_urls'])}"
        send_to_line_group(post_info)
            
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ–°è²¼æ–‡
        if is_post_exists(latest_post['id']):
            send_to_line_group("ğŸ”„ è©²è²¼æ–‡å·²è™•ç†éï¼Œè·³éç¿»è­¯å’Œæ¨é€ã€‚")
            return
            
        # åˆ†æä¸¦ç¿»è­¯å…§å®¹
        send_to_line_group("ğŸ”„ æ­£åœ¨åˆ†æä¸¦ç¿»è­¯å…§å®¹...")
        processed_content = analyze_content(latest_post)
        
        if not processed_content:
            send_to_line_group("âŒ å…§å®¹è™•ç†å¤±æ•—ï¼Œå¯èƒ½æ˜¯ DeepSeek API å•é¡Œã€‚")
            return
            
        # æ§‹å»º LINE æ¶ˆæ¯
        content_type = "å½±ç‰‡" if processed_content['is_video'] else "æ–‡å­—"
        message = f"ğŸ”” Trump åœ¨ Truth Social æœ‰æ–°å‹•æ…‹ï¼\n\nğŸ“ é¡å‹: {content_type}\n\nğŸ‡ºğŸ‡¸ åŸæ–‡:\n{processed_content['original_content']}\n\nğŸ‡¹ğŸ‡¼ ä¸­æ–‡ç¿»è­¯:\n{processed_content['translated_content']}"
        
        # å¦‚æœæœ‰åª’é«”ï¼Œé™„åŠ åª’é«” URL
        if processed_content['media_urls']:
            message += "\n\nğŸ–¼ï¸ åª’é«”é€£çµ:\n" + "\n".join(processed_content['media_urls'])
        
        # ç™¼é€åˆ° LINE ç¾¤çµ„
        if send_to_line_group(message):
            # ä¿å­˜å·²è™•ç†çš„è²¼æ–‡
            save_post(processed_content['id'], processed_content['original_content'])
            send_to_line_group("âœ… è™•ç†å®Œæˆï¼Œè²¼æ–‡å·²ä¿å­˜ã€‚")
        
    except Exception as e:
        error_message = f"âŒ åŸ·è¡Œéç¨‹ä¸­å‡ºéŒ¯: {str(e)}"
        logger.error(error_message)
        send_to_line_group(error_message)
